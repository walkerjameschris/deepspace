---
title: "Using Neural Networks to Classify American Sign Language (ASL) Signs"
author: "Chris Walker"
format: pdf
editor: visual
---

```{r setup, echo=FALSE}
library(deepspace, quietly = TRUE)
library(ggplot2, quietly = TRUE)

add_caption <- function(plot, text) {
  
  id <- as.numeric(Sys.getenv(".id"))
  id <- dplyr::coalesce(id + 1, 1)
  Sys.setenv(".id" = id)

  plot +
    ggplot2::labs(
      caption = glue::glue("Figure {id}: {text}")
    ) +
    ggplot2::theme(
      plot.caption = ggplot2::element_text(hjust = 0.5)
    )
}
```

# Problem Statement and Introduction

Machine learning plays a unique role in improving accessibility in digital communication. This includes services like text-to-speech, language translation, and alt-text generation. Machine learning could also be used to detect American Sign Language (ASL) signs and convert them to text data. **Sign language detection is not currently implemented into the modern ecosystem of video call tools.** Imagine if FaceTime was able to convert signs to text in real time. An ASL user could sign into the camera, convert their message to text, and have it read back as text-to-speech. This could create more natural telecommunication for people with a hearing disability. With this concept in mind, I set out to create a primitive sign language detection model by implementing the learning algorithms from scratch.

Beyond this report, this project is an R package (called `deepspace`) with a C++ back end which aids in the collection, preprocessing, and modeling of images for the purpose of classification. I hosted and documented this package on my [personal GitHub profile here](https://github.com/walkerjameschris/deepspace). Additionally, it is important to set reasonable expectations for this class project; while a fully featured model would capture the entirety of ASL, this model classifies several letters of the ASL alphabet as a proof of concept. Users can install this package on their system and launch a webcam stream to classify a handful of ASL digits if they choose.

# Data Sources

This model was trained on images captured using my webcam. At the time of capture, I pre-select a sign which I was going to perform. I captured $n$ images in rapid succession. I performed the sign in a variety of lighting conditions and angles while the webcam was capturing. Because I *pre-selected* the sign, there was no need to label images individually as all images are stored in a directory that corresponds to that sign. I repeated this process for ASL letters A, B, and C. Images contain values from 0 to 1 corresponding to the brightness of the pixel.

```{r echo=FALSE, fig.align='center', fig.height=2, fig.width=6}
image_plot <-
  list(
    a = 1,
    b = 750,
    c = 1059
  ) |>
  purrr::map(function(i) {
    
    img <- deepspace:::asl$X[i, ]
    
    as.vector(img) |>
      tibble::as_tibble() |>
      dplyr::mutate(
        i = dplyr::row_number(),
        x = i %%  42,
        y = 0 - i %/% 42
      ) |>
      dplyr::add_row(
        x = 0, y = 0,
        i = 0, value = 0.8
      )
    
  }) |>
  dplyr::bind_rows(
    .id = "letter"
  ) %>%
  dplyr::mutate(
    value = value
  ) |>
  ggplot2::ggplot(
    ggplot2::aes(
      x = x,
      y = y,
      fill = value,
      color = value
    )
  ) +
  ggplot2::geom_tile() +
  ggplot2::facet_wrap(
    ~ toupper(letter)
  ) +
  ggplot2::coord_fixed() +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    legend.position = "none",
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank()
  )

add_caption(
  plot = image_plot,
  text = "Example images pre-vectorization"
)
```

Stemming from other assignments this semester, I *vectorized* all images captured by the webcam. I can point to a directory which corresponds to a given sign and loads, vectorize, and labels all images as R matrices for use in training. The matrices of images were split into training and testing for validation.

```{r, echo=FALSE, fig.align='center', fig.height=1.5, fig.width=6}
images <-
  tibble::tibble(
    x = seq(3)
  ) |>
  tidyr::uncount(
    weights = 3,
    .id = "y"
  ) |>
  tidyr::uncount(
    weights = 3,
    .id = "image"
  ) |>
  dplyr::mutate(
    image = (image - 1) * 0.2,
    x = x + image,
    y = y + image
  ) |>
  dplyr::arrange(
    desc(image)
  )

matrices <-
  tibble::tibble(
    x = seq(9) + 5
  ) |>
  tidyr::uncount(
    weights = 3,
    .id = "y"
  ) |>
  dplyr::mutate(
    image = (y - 1) * 0.2
  )

matrix_plot <-
  dplyr::bind_rows(
    images,
    matrices
  ) |>
  ggplot2::ggplot(
    ggplot2::aes(
      x = x,
      y = y,
      group = image,
      color = 0 - image
    )
  ) +
  ggplot2::geom_point(
    shape = 15,
    size = 5
  ) +
  ggplot2::coord_fixed() +
  ggplot2::scale_y_continuous(
    limits = c(0.5, 5)
  ) +
  ggplot2::scale_x_continuous(
    limits = c(0.5, 15)
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    legend.position = "none",
    panel.grid = ggplot2::element_blank(),
    axis.text = ggplot2::element_blank(),
    axis.title = ggplot2::element_blank()
  ) +
  ggplot2::geom_curve(
    data = tibble::tibble(x = 4),
    inherit.aes = FALSE,
    curvature = -0.2,
    ggplot2::aes(
      x = x,
      y = 4.5,
      xend = 7,
      yend = 4
    ),
    arrow = ggplot2::arrow(
      length = ggplot2::unit(0.1, "inches"),
      type = "closed"
    )
  ) +
  ggplot2::geom_text(
    inherit.aes = FALSE,
    ggplot2::aes(
      x = x,
      y = y,
      label = label
    ),
    data = tibble::tibble(
      x = c(2.5, 9.9),
      y = c(4.5, 4.0),
      label = c("Images", "Vectorized")
    )
  )

add_caption(
  plot = matrix_plot,
  text = "Image vectorization"
)
```

Images were originally 3,024 pixels wide and tall. Because each pixel is mapped to an input neuron, this means that the model would have $3024^2$ weights and biases within the input layer. To balance computational efficiency and model complexity, I down scaled all images by a factor of 72 to create images 42 pixels wide and tall. This is still a sufficient level of detail for a total of $42^2$ weights and biases in the input layer.

I captured 1,543 images to train and test my model. I recognize that deep learning models require large amounts of data to effectively learn complex relationships in data, especially images. For this reason, I used image augmentation to artificially increase the number of images to increase model robustness.

I added 3 levels of Gaussian noise to the images for a 3x increase in the number of samples. I also applied 6 levels of brightness adjustment decrease in image brightness for a final 6x increase. There are now a total of 27,774 images in consideration with 20,000 used for training and 774 used for testing.

# Methodology

The process of capturing images as part of this process is fairly linear. In general, I captured images following the procedure described in *Data Sources* and stored them for model validation. However, the process of modeling the images was more iterative in nature. It involved making updates to the underlying algorithm while also tuning hyperparameters such as the number of hidden layer neurons and the learning rate

Post data collection, I constructed a tuning grid which considers all possible hyperparameter combinations. Completing the Cartesian product of all settings may not be feasible for larger machine learning models. However, my models trained in an acceptable amount of time such that all combinations could be tried. The results of these trials are discussed in detail in the next section.

While the code package only contains a few core functions used for model estimation, the package contains many other functions designed to aid the model estimation procedure written in C++. Most of these functions correspond to a specific linear algebra operation needed to fit and validate a neural network.

#### `normal_matrix(row, col)`

This function initializes a matrix with dimensions *row* and *col* such that each element is randomly drawn from a normal distribution with mean zero and a standard deviation of one. While other methods exist to initialize a neural network for training, I find that randomly distributed noise works well in many cases. I also supply a random seed which ensures I can reproduce random noise and achieve the same estimations given the same training data and hyperparameter configurations. Let $X$ be a matrix with $i$ rows and $j$ columns.

$$
f(i, j) = X
$$

$$
X_{ij} \approx \mathcal{N}(0, 1)
$$

#### `mul(X, Y)`

Matrix multiplication is an extremely common operation in machine learning and fitting a neural network is no exception. This function considers two matrices where matrix $X$ must have the same number of rows as matrix $Y$ has columns. It returns a matrix with the number of rows of $X$ and the number of columns as $Y$. This function is highly optimized and benchmarks at speeds equal to or faster than R's base matrix multiplication implementation.

$$
XY
$$

#### `transpose(X)`

Like matrix multiplication, the transpose operation is a core linear algebra operation. This function simply considers matrix $X$ and returns a new matrix which has as many rows as $X$ has columns and as many columns as $X$ has rows. It inverts the positions of row-column pairs as iterates across the matrix.

$$
X^T
$$

#### `multiply(X, Y)`

Unlike matrix multiplication, this function performs element-wise multiplication of two matrices (Hadamard product). Because this is an element level multiplication, matrices $X$ and $Y$ must share the same dimensions. As such, this function returns a new matrix with the same dimensions as the input matrices.

$$
X \odot Y
$$

#### `subtract(X, Y)`

This function operates like the `multiply()` function to perform element-wise subtraction of two matrices. Thus, the input matrices $X$ and $Y$ must again share the same dimensions such that a new matrix with the same dimensions can be returned. It is important to note that matrix $Y$ is always subtracted *from* matrix $X$.

$$
X - Y
$$

#### `sub_scalar(x, Y)`

Unlike `subtract()`, this function allows for the subtraction of a matrix *from* a scalar value. Because C++ is highly procedural, this function is needed to define behavior separately from element-wise subtraction. It accepts a scalar parameter $x$ and a matrix *Y* and returns a new matrix with the same dimensions as $Y$.

$$
X =\begin{bmatrix}
x & \dots & x\\
\vdots & \ddots & \vdots\\
x & \dots & x
\end{bmatrix}
$$

$$
XI - Y
$$

#### `mul_scalar(x, Y)`

Like `sub_scalar()`, this function implements a scalar multiplication procedure. However, because it is multiplication the explicit order of the operation does not matter. In either case, this function accepts a scalar $x$ and a matrix $Y$ and returns a new matrix with the same dimensions as $Y$.

$$
xY
$$

#### `add_ones(X)`

This function does not implement a standard linear algebra operation but is rather a convenience functionality used during network feed-forward to introduce a new column vector of ones to a matrix of arbitrary dimensions. This is needed to allow for a *bias* to be estimated for each layer in the network as we will see in later sections. Let $X$ be a matrix with $i$ rows and $j$ columns. Matrix $Y$ represents matrix $X$ with a column vector of ones appended to the right side.

$$
Y =\begin{bmatrix}
X_{11} & \dots & X_{1j} & 1\\
\vdots & \ddots & \vdots & 1\\
X_{i1} & \dots & X_{ij} & 1
\end{bmatrix}
$$

#### `activation(X)`

This function considers element-wise activation during model feed-forward. Specifically, it implements the logistic function (sometimes called the sigmoid function). This is needed to take unbounded values and *squish* them between values of zero and one. It is the same function that logistic regression uses to convert $X\beta$ values to a probability. This is necessary for neural networks to keep values sensible as they traverse the network. It also helps demonstrate the similarities between neural networks and logistic regression!

$$
f(x) = \frac{e^x}{1 + e^x}
$$

$$
X_a=\begin{bmatrix}
f(X_{11}) & \dots & f(X_{1j})\\
\vdots & \ddots & \vdots\\
f(X_{i1}) & \dots & f(X_{ij})
\end{bmatrix}
$$

#### `feed_forward(X)`

The concept of *feeding forward* is an important concept in neural network fitting and prediction. The core concept it is to multiply the result of the prior step with the weight matrix at the current step. The resulting matrix will have the same rows as the input matrix and the same number of columns as there are classes in our training label matrix (one-hot encoded). The `deepspace` package fits neural networks with two hidden layers each with an arbitrary number of neurons.

Let our training data be denoted as $X$, the weights for hidden layer one as $H_1$, the weights for hidden layer two as $H_2$, the weight for the final layer as $W$. Where $f()$ corresponds to `add_ones()` from above.

$$
f(f(f(XH_1)H_2)W)
$$

#### `gradient()`

This function is the heart of the back propagation algorithm. It is used to compute the gradient such that the weights and biases can be adjusted to maximize cross product entropy through the process of gradient descent. It represents the derivative of the cost function with respect to each term in the network. If a gradient can be found, we *subtract* the gradient from the current matrix of weights to better the model fit. Let $W$ be a matrix of weights for the current layer, $D$ is a matrix of differences, and $A$ is the activation matrix from the current layer. This gradient is derived from the cross-entropy loss function.

$$
L = -\sum_{i=1}^m y_i\log a
$$

$$
G = WD^T \times (A \times(1 - A))
$$

#### Model Fitting Procedure

The core function of this package is `deepspace::fit_network()`. This function accepts training data and labels and fits a neural network. During initialization, all weight matrices are constructed using `normal_matrix()` in accordance with network design criteria. Suppose we have a matrix of training data denoted as $X$ with 6 predictors and $n$ observations. Additionally, we will be fitting a binary classification outcome (which is one hot encoded in the label matrix $Y$ with 2 columns). The network will have two hidden layers each with 3 neurons. Matrix $X_T$ represents the training matrix $X$ with an intercept column vector added. All $W$ matrices represent weights for the hidden layers and the output layer. Here $f()$ refers to the `normal_matrix()` function.

$$
X_T =\begin{bmatrix}
X_{1,1} & \dots & X_{1,6} & 1\\
\vdots & \ddots & \vdots & 1\\
X_{n,1} & \dots & X_{n,6} & 1
\end{bmatrix}
$$

$$
W_1 = f(7, 3)
$$

$$
W_2 = f(6, 3)
$$

$$
W_3 = f(6, 2)
$$

The learning procedure takes this baseline network and begins backpropagation. It repeats this process for a predetermined number of epochs or until some other stop condition is applied (i.e., a minimum change denoted as $\epsilon$). Matrices denoted as $D$ are known as *difference* matrices.

$$
D_3 = A_3 - Y
$$

$$
D_2 = W_3D_3^T \times (A_2 \times(1 - A_2))
$$

$$
D_1 = W_2D_2^T \times (A_1 \times(1 - A_1))
$$

We can now apply these matrices to update the three weight matrices. An additional parameter is introduced here as $\gamma$ which represents the learning rate. Currently, `deepspace` supports only a constant learning rate across all three weight matrix computations.

$$
W_1 = W_1 - \gamma X^TD_1
$$

$$
W_2 = W_2 - \gamma A_1^TD_2
$$

$$
W_3 = W_3 - \gamma A_2^TD_3
$$

The package allows for printing of neural networks such that each weight is encoded as a line and each bias is encoded as a circle. In the example above we defined a 7-3-3-2 matrix. While we have 6 predictors, the network has one additional predictor (the bias) moving to 7 predictors.

```{r, echo=FALSE, fig.height=3, fig.width=4, fig.align='center'}
X <- matrix(seq(6), nrow = 1)
Y <- matrix(seq(2), nrow = 1)

nx <- deepspace::fit_network(X, Y)

graph <-
  plot(nx) +
  ggplot2::theme(
    legend.position = "none",
    plot.title = element_blank(),
    plot.subtitle = element_blank()
  )

add_caption(
  plot = graph,
  text = "An example neural network"
)
```

# Hypothesis

Before setting out on model estimations, I wanted to outline some key hypothesis statements to better my intuition for these models. First, I expect that there are diminishing marginal returns to model performance for an increase in the number of hidden layer neurons. Therefore, a network with 2 hidden layers each with 20 neurons may be sufficient. Additionally, I expect that the logistic activation function will be sufficient for model training.

While an increased number of neurons, hidden layers, or training epochs may marginally improve performance, I expect that a fairly simple model will perform adequately for the purposes of image classification. I detailed the performance of each model training configuration and identified a candidate model in the section below.

# Evaluation and Final Results

\<robust discussion of results\>
